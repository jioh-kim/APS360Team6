{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THz8nEmmRcAf"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfEwnLErRel8"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_YwLwCqS6w"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-datasets librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZAVKWS5R1_J"
      },
      "source": [
        "Only grab the dataset where instument == keyboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vcosBrKmKQev"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Constants\n",
        "KEYBOARD_FAMILY_LABEL = 4 # According to NSynth dataset family label\n",
        "SAMPLE_RATE = 16000\n",
        "TRIM_LENGTH = 3 * SAMPLE_RATE  # Trim to the first 3 seconds\n",
        "\n",
        "# Define the processing function\n",
        "def process_data(example):\n",
        "    audio = example['audio']\n",
        "    instrument_family = example['instrument']['family']\n",
        "    pitch = example['pitch']\n",
        "\n",
        "    # Filter keyboard samples\n",
        "    is_keyboard = tf.equal(instrument_family, KEYBOARD_FAMILY_LABEL)\n",
        "    # Only process the samples where is_keyboard is True\n",
        "    def process_keyboard_sample(audio, pitch):\n",
        "        # Trim the audio\n",
        "        audio = audio[:TRIM_LENGTH]\n",
        "\n",
        "        # # Convert audio to CQT (Constant-Q Transform) using librosa\n",
        "        # # Set fmin to the frequency of A0 and n_bins to 88\n",
        "        # def compute_cqt(x):\n",
        "        #     return np.abs(librosa.cqt(x, sr=SAMPLE_RATE, fmin=librosa.note_to_hz('A0'), n_bins=88, bins_per_octave=12))\n",
        "\n",
        "        # Here, tf.numpy_function applies a Python function to the TensorFlow tensor\n",
        "        # audio = tf.numpy_function(compute_cqt, [audio], tf.float32)\n",
        "\n",
        "        # Modify pitch\n",
        "        pitch = pitch - 21\n",
        "        return audio, pitch\n",
        "    # Return the processed audio and pitch, only if the sample is a keyboard\n",
        "    return tf.cond(is_keyboard, lambda: process_keyboard_sample(audio, pitch), lambda: (audio, pitch))\n",
        "\n",
        "def filter_keyboard_samples(example):\n",
        "    return tf.equal(example['instrument']['family'], KEYBOARD_FAMILY_LABEL)\n",
        "\n",
        "def get_data_loader(data_split, batch_size=64, num_batches=None):\n",
        "    ds = tfds.load('nsynth', split=data_split, as_supervised=False)\n",
        "\n",
        "    # First, filter out non-keyboard samples\n",
        "    ds = ds.filter(filter_keyboard_samples)\n",
        "    ds = ds.map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.filter(lambda audio, pitch: tf.reduce_sum(tf.shape(audio)) > 0)  # Filter out empty audio results\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    if num_batches:\n",
        "        ds = ds.take(num_batches)\n",
        "\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Input to model\n",
        "batch_size = 64\n",
        "train_loader = get_data_loader('train', batch_size, num_batches=40)\n",
        "val_loader = get_data_loader('valid', batch_size, num_batches=6)\n",
        "test_loader = get_data_loader('test', batch_size, num_batches=6)\n",
        "classes = list(range(88))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8IGad4g33Vwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01e3975-4765-4690-b3ae-41d5a614fd99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample audio max value: 0.46275418996810913\n",
            "First sample audio min value: -0.46886491775512695\n",
            "First sample audio range: 0.9316191077232361\n",
            "First sample pitch: 85\n"
          ]
        }
      ],
      "source": [
        "for audio, pitch in train_loader.take(1):\n",
        "    first_sample_audio = audio[0]\n",
        "    first_sample_pitch = pitch[0]\n",
        "\n",
        "    # Calculate the maximum and minimum values\n",
        "    max_value = tf.reduce_max(first_sample_audio)\n",
        "    min_value = tf.reduce_min(first_sample_audio)\n",
        "\n",
        "    # Calculate the range (max - min)\n",
        "    range_value = max_value - min_value\n",
        "\n",
        "    print(f\"First sample audio max value: {max_value.numpy()}\")\n",
        "    print(f\"First sample audio min value: {min_value.numpy()}\")\n",
        "    print(f\"First sample audio range: {range_value.numpy()}\")\n",
        "    print(f\"First sample pitch: {first_sample_pitch.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_length(data_loader):\n",
        "    length = 0\n",
        "    for _ in data_loader:\n",
        "        length += 1\n",
        "    return length\n",
        "\n",
        "# Use this function to get the length of your data loaders\n",
        "test_loader_length = get_dataset_length(test_loader)\n",
        "val_loader_length = get_dataset_length(val_loader)\n",
        "train_loader_length = get_dataset_length(train_loader)\n",
        "\n",
        "print(f\"Test loader length: {test_loader_length}\")\n",
        "print(f\"Validation loader length: {val_loader_length}\")\n",
        "print(f\"Train loader length: {train_loader_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtGkBcScNX6O",
        "outputId": "30ab3c2e-8587-4bb7-c18b-65dd56930408"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loader length: 6\n",
            "Validation loader length: 6\n",
            "Train loader length: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_sample_count(data_loader):\n",
        "    total_samples = 0\n",
        "    for audio, pitch in data_loader:\n",
        "        # Count the number of samples in each batch\n",
        "        batch_samples = tf.shape(audio)[0]  # assuming audio is a 2D tensor [batch_size, features]\n",
        "        total_samples += batch_samples\n",
        "    return total_samples\n",
        "\n",
        "# Use this function to get the number of samples in your data loaders\n",
        "test_samples_count = get_dataset_sample_count(test_loader)\n",
        "val_samples_count = get_dataset_sample_count(val_loader)\n",
        "train_samples_count = get_dataset_sample_count(train_loader)\n",
        "\n",
        "print(f\"Train loader samples: {train_samples_count}\")\n",
        "print(f\"Validation loader samples: {val_samples_count}\")\n",
        "print(f\"Test loader samples: {test_samples_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOqZSyzqZOqp",
        "outputId": "1610605c-89fa-4829-f7f2-72793ffebaae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader samples: 2560\n",
            "Validation loader samples: 384\n",
            "Test loader samples: 384\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}