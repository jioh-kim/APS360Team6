{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THz8nEmmRcAf"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfEwnLErRel8"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_YwLwCqS6w"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-datasets librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZAVKWS5R1_J"
      },
      "source": [
        "Only grab the dataset where instument == keyboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Constants\n",
        "KEYBOARD_FAMILY_LABEL = 4 # According to NSynth dataset family label\n",
        "SAMPLE_RATE = 16000\n",
        "TRIM_LENGTH = 3 * SAMPLE_RATE  # Trim to the first 3 seconds\n",
        "\n",
        "def process_data(example):\n",
        "    audio = example['audio']\n",
        "    instrument_family = example['instrument']['family']\n",
        "    pitch = example['pitch']\n",
        "\n",
        "    is_keyboard = tf.equal(instrument_family, KEYBOARD_FAMILY_LABEL)\n",
        "\n",
        "    def process_keyboard_sample(audio, pitch):\n",
        "        audio = audio[:TRIM_LENGTH]\n",
        "        if pitch < 21:\n",
        "            # Instead of returning None, return a marker (e.g., a zero-length tensor)\n",
        "            return tf.zeros((0,)), tf.constant(-1, dtype=tf.int64)\n",
        "        else:\n",
        "            pitch = pitch - 21\n",
        "            return audio, pitch\n",
        "\n",
        "    return tf.cond(is_keyboard, lambda: process_keyboard_sample(audio, pitch), lambda: (audio, pitch))\n",
        "\n",
        "def filter_keyboard_samples(example):\n",
        "    return tf.equal(example['instrument']['family'], KEYBOARD_FAMILY_LABEL)\n",
        "\n",
        "def filter_invalid_samples(audio, pitch):\n",
        "    # Check if the sample is valid (not marked for removal)\n",
        "    return tf.size(audio) > 0 and tf.not_equal(pitch, -1)\n",
        "\n",
        "def get_data_loader(data_split, batch_size=64, num_batches=None):\n",
        "    ds = tfds.load('nsynth', split=data_split, as_supervised=False)\n",
        "\n",
        "    ds = ds.filter(filter_keyboard_samples)\n",
        "    ds = ds.map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.filter(filter_invalid_samples)\n",
        "    ds = ds.batch(batch_size)\n",
        "    if num_batches:\n",
        "        ds = ds.take(num_batches)\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "RKOifdhZeOT-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to model\n",
        "batch_size = 64\n",
        "train_loader = get_data_loader('train', batch_size, num_batches=40)\n",
        "val_loader = get_data_loader('valid', batch_size, num_batches=6)\n",
        "test_loader = get_data_loader('test', batch_size, num_batches=6)\n",
        "classes = list(range(88))\n",
        "\n",
        "for audio, pitch in train_loader.take(5):\n",
        "    print(pitch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qV0GWm8gC0r",
        "outputId": "8f521a27-3021-4bf0-b13b-fd2853457703"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[85 10 60 33 48 84 21 54 13 33  0  6 49 52 56 17  4 74  6 40 63 20 44 41\n",
            "  7 22 67 64  8 78 16 48 14 29 87 32 70 84 65 66 30 56 28 85 47 33 24 49\n",
            " 81 18 21 51 34 61 36  8 10 45 61 70 74 33 57 52], shape=(64,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[42 16 62 72 38 63 72 58 35 40 68 67 22  3 47 57 68 77 50 28 45 46 33 65\n",
            " 30 22 10 74  5 16 81 52 70 27 58 49 17 14 52 19 19 84 15 86 67 16 11 65\n",
            " 25 55 53 15 24 72 73 51 37  6 76 24 72 13 25 41], shape=(64,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[79 31 60 45 83 38 28 25 56  9 38 43 52 86 25 57 16 27 25 25 21 76 59 43\n",
            " 46 64 43 13 85 26  7 36 54  6 19 39 23  2 34 21 40 54 30 65 55 14 28 49\n",
            " 86 22 16 54 35 34 70 67 19 30 76 26 31 22 69 59], shape=(64,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[59 56 43 62 74 17 15 56 73 67 34 10 73 48 35 41 42 20 67 85 45 17 55 26\n",
            "  0 16 22 24 87 21 38 70 25 44 71 43 15  3 26 25 52 39 59 17 19 59 41 86\n",
            " 55 15 13 79 69 42 33 63 32 16 66 49 61 61 47 65], shape=(64,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 9 45 68 46 39 45  0 19 35 67 18 82 22 74 23 22 68 18 24 78 29 67 61 21\n",
            " 68 45 33 14 30 12 31 39  9 15 64 30 39 37 59 47 10 60 65 74 24 35 51  0\n",
            " 48 19 38 72 27 81  6 32 23 26 21 24 42 24 64 43], shape=(64,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8IGad4g33Vwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a9c3b0-698e-4be1-abcf-cda72a87ecc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample audio max value: 0.46275418996810913\n",
            "First sample audio min value: -0.46886491775512695\n",
            "First sample audio range: 0.9316191077232361\n",
            "First sample pitch: 85\n"
          ]
        }
      ],
      "source": [
        "# printing a sample audio and pitch value\n",
        "for audio, pitch in train_loader.take(1):\n",
        "    first_sample_audio = audio[0]\n",
        "    first_sample_pitch = pitch[0]\n",
        "\n",
        "    # Calculate the maximum and minimum values\n",
        "    max_value = tf.reduce_max(first_sample_audio)\n",
        "    min_value = tf.reduce_min(first_sample_audio)\n",
        "\n",
        "    # Calculate the range (max - min)\n",
        "    range_value = max_value - min_value\n",
        "\n",
        "    print(f\"First sample audio max value: {max_value.numpy()}\")\n",
        "    print(f\"First sample audio min value: {min_value.numpy()}\")\n",
        "    print(f\"First sample audio range: {range_value.numpy()}\")\n",
        "    print(f\"First sample pitch: {first_sample_pitch.numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get number of batches in each loader\n",
        "def get_dataset_length(data_loader):\n",
        "    length = 0\n",
        "    for _ in data_loader:\n",
        "        length += 1\n",
        "    return length\n",
        "\n",
        "# Use this function to get the length of your data loaders\n",
        "test_loader_length = get_dataset_length(test_loader)\n",
        "val_loader_length = get_dataset_length(val_loader)\n",
        "train_loader_length = get_dataset_length(train_loader)\n",
        "\n",
        "print(f\"Train loader length: {train_loader_length}\")\n",
        "print(f\"Validation loader length: {val_loader_length}\")\n",
        "print(f\"Test loader length: {test_loader_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtGkBcScNX6O",
        "outputId": "20fee94e-1bb5-4d82-ca2c-03fe082c4634"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader length: 40\n",
            "Validation loader length: 6\n",
            "Test loader length: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get number of samples in each loader\n",
        "def get_dataset_sample_count(data_loader):\n",
        "    total_samples = 0\n",
        "    for audio, pitch in data_loader:\n",
        "        # Count the number of samples in each batch\n",
        "        batch_samples = tf.shape(audio)[0]  # assuming audio is a 2D tensor [batch_size, features]\n",
        "        total_samples += batch_samples\n",
        "    return total_samples\n",
        "\n",
        "# Use this function to get the number of samples in your data loaders\n",
        "test_samples_count = get_dataset_sample_count(test_loader)\n",
        "val_samples_count = get_dataset_sample_count(val_loader)\n",
        "train_samples_count = get_dataset_sample_count(train_loader)\n",
        "\n",
        "print(f\"Train loader samples: {train_samples_count}\")\n",
        "print(f\"Validation loader samples: {val_samples_count}\")\n",
        "print(f\"Test loader samples: {test_samples_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOqZSyzqZOqp",
        "outputId": "c9712806-9005-4574-c565-2fcaef33f00d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader samples: 2560\n",
            "Validation loader samples: 384\n",
            "Test loader samples: 384\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}